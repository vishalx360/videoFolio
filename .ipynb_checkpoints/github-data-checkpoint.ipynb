{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import datetime\n",
    "import random\n",
    "from itertools import cycle\n",
    "import traceback\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import fromstring\n",
    "def get_proxies():\n",
    "    url = 'https://free-proxy-list.net/'\n",
    "    response = requests.get(url)\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:10]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):\n",
    "            #Grabbing IP and corresponding PORT\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'190.211.241.149:8081'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxies = list(get_proxies())\n",
    "\n",
    "proxy_pool = cycle(proxies)\n",
    "\n",
    "proxy = next(proxy_pool)\n",
    "# proxy='https://51.75.147.35:80'\n",
    "\n",
    "proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"Vivek Shah\",\n",
      " \"bio\": \"Into Python and NodeJs, Also business.\",\n",
      " \"avatar\": \"https://avatars2.githubusercontent.com/u/34334421?v=4\",\n",
      " \"repo_count\": 25,\n",
      " \"company\": null,\n",
      " \"most recent repo\": [\n",
      "  \"https://api.github.com/repos/vivekshah1801/Codechef-Solution-Downloader\",\n",
      "  \"https://api.github.com/repos/vivekshah1801/Lazy-Coder\",\n",
      "  \"https://api.github.com/repos/vivekshah1801/Detoxify\"\n",
      " ],\n",
      " \"contribution\": \"276\",\n",
      " \"language\": [\n",
      "  \"JavaScript\",\n",
      "  \"HTML\",\n",
      "  \"Python\"\n",
      " ],\n",
      " \"total_contributed_repo\": 30,\n",
      " \"popular_contribution\": [\n",
      "  \"https://github.com/anmolsaxena10/CSIWebsite\",\n",
      "  \"https://github.com/LockedUp-Coders/reference-code\",\n",
      "  \"https://github.com/YashKumarVerma/attendance-backend\"\n",
      " ],\n",
      " \"twitter\": \"vivekshah1801\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "username=\"vivekshah1801\"\n",
    "repo=[]\n",
    "star={}\n",
    "popular_repo={}\n",
    "language=[]\n",
    "contributed_repo=[]\n",
    "popular_contributed_repo={}\n",
    "url_for_api='https://api.github.com/users/'+username+'?access_token=7d5bfe7c15f4f7a27341f8372b28ff84ec5e089f'\n",
    "date_repo={}\n",
    "## --- Get User data from username ---- ##\n",
    "data=requests.get(url_for_api )\n",
    "data=data.text\n",
    "data=json.loads(data)\n",
    "\n",
    "# print(data)\n",
    "## --- Get repository data from repo_url ---- ##\n",
    "repo_url=data['repos_url']\n",
    "repo_data=requests.get(repo_url+'?access_token=7d5bfe7c15f4f7a27341f8372b28ff84ec5e089f')\n",
    "repo_data=repo_data.text\n",
    "repo_data=json.loads(repo_data)\n",
    "# print(repo_data[0]['url'])\n",
    "\n",
    "## --- Get name of repository --- ##\n",
    "for i in range(0,len(repo_data)):\n",
    "    flag=0\n",
    "    \n",
    "    ## --- Get repository url --- ##\n",
    "    url=repo_data[i]['url']\n",
    "    date=repo_data[i]['created_at']\n",
    "    date=date.split('T')\n",
    "    date=date[0]\n",
    "    date_repo.__setitem__(date,url)\n",
    "#     print(url)\n",
    "    url_data=requests.get(url+'?access_token=7d5bfe7c15f4f7a27341f8372b28ff84ec5e089f')\n",
    "    url_data=url_data.text\n",
    "    url_data=json.loads(url_data)\n",
    "    \n",
    "    ## ---- Get Star of particular repository ---- ##\n",
    "    star_url=repo_data[i]['stargazers_url']+'?access_token=7d5bfe7c15f4f7a27341f8372b28ff84ec5e089f'\n",
    "    star_data=requests.get(star_url)\n",
    "    star_data=star_data.text\n",
    "    star_data=json.loads(star_data)\n",
    "    language.append(repo_data[i]['language'])\n",
    "    if(len(star_data)>5 and flag==1):\n",
    "        \n",
    "        popular_repo.__setitem__(repo_data[i]['name'],len(star_data))\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        \n",
    "        contributed_repo.append(repo_data[i]['name'])\n",
    "#         print(url_data['parent']['html_url'])\n",
    "        star.__setitem__(url_data['parent']['forks'],url_data['parent']['html_url'])\n",
    "    except:\n",
    "        flag=1\n",
    "        repo.append(repo_data[i]['name'])\n",
    "\n",
    "# dates = [datetime.datetime.strptime(ts, \"%Y-%m-%d\") for ts in date_repo]\n",
    "# dates.sort()\n",
    "\n",
    "date_repo=dict(sorted(date_repo.items(),key = lambda x: x[0],reverse=True) )\n",
    "# print(date_repo)\n",
    "# print(len(popular_repo))\n",
    "if(len(popular_repo)==0):\n",
    "    repos=list(date_repo.values())\n",
    "    if(len(repos)>4):\n",
    "#         label=\"most recent repo\"\n",
    "        repos=repos[0:3]\n",
    "# print(repos)\n",
    "sorted_fork={}\n",
    "\n",
    "sorted_fork = sorted(star.items(), key=lambda kv: kv[0])\n",
    "sorted_fork=dict(sorted_fork)\n",
    "list_fork=list(sorted_fork.values())\n",
    "# print(list_fork)\n",
    "list_no_fork=list(sorted_fork.keys())\n",
    "# print(list_no_fork)\n",
    "try:\n",
    "    if(list_no_fork[0]>10):\n",
    "        if(len(list_fork)>4):\n",
    "            list_fork=list_fork[0:3]\n",
    "        else:\n",
    "            list_fork=list_fork\n",
    "    else:\n",
    "        if(len(list_fork)>4):\n",
    "            list_fork=list_fork[0:3]\n",
    "        else:\n",
    "            list_fork=list_fork\n",
    "except:\n",
    "    if(len(list_fork)>4):\n",
    "            list_fork=list_fork[0:3]\n",
    "    else:\n",
    "            list_fork=list_fork\n",
    "        \n",
    "\n",
    "# print(list_fork)\n",
    "##  --- Get top 3 language --- ## \n",
    "language = [i for i in language if i] \n",
    "lang=Counter(language)\n",
    "lang=dict(lang)\n",
    "sorted_x = sorted(lang.items(), key=lambda kv: kv[1],reverse=True)\n",
    "sorted_lang=dict(sorted_x)\n",
    "list_lang=list(sorted_lang.keys())\n",
    "if(len(list_lang)>4):\n",
    "    list_lang=list_lang[0:3]\n",
    "else:\n",
    "    list_lang=list_lang\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "## --- Scrap Contribution of user ---- ##\n",
    "url='https://github.com/'+username\n",
    "cont_data=requests.get(url)\n",
    "\n",
    "cont_data=cont_data.text\n",
    "soup = BeautifulSoup(cont_data, 'html.parser')\n",
    "cont_data = soup.findAll(\"h2\", {\"class\": \"f4 text-normal mb-2\"})\n",
    "cont_data=cont_data[0].text.strip()\n",
    "temp = re.findall(r'\\d+', cont_data) \n",
    "if(len(popular_repo)==0):\n",
    "    \n",
    "    data_dict={'name':data['name'],'bio':data['bio'],'avatar':data['avatar_url'],'repo_count':len(repo),'company':data['company'],'most recent repo':repos,'contribution':temp[0],'language':list_lang,'total_contributed_repo':len(contributed_repo),'popular_contribution':list_fork,'twitter':data['twitter_username']}\n",
    "else:\n",
    "    data_dict={'name':data['name'],'bio':data['bio'],'avatar':data['avatar_url'],'repo_count':len(repo),'company':data['company'],'popular_repo':popular_repo,'contribution':temp[0],'language':list_lang,'total_contributed_repo':len(contributed_repo),'popular_contribution':list_fork,'popular_repo':popular_repo,'twitter':data['twitter_username']}\n",
    "\n",
    "\n",
    "data_dict=json.dumps(data_dict, indent = 1)\n",
    "\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datesorted(date_repo, key=lambda d: map(int, d.split('-')))\n",
    "date_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-02-02', '2020-09-03']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(popular_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
